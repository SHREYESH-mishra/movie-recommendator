{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dd6543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dell\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.12\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baac4c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/tmdb/tmdb-movie-metadata?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.89M/8.89M [00:03<00:00, 3.08MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tmdb/tmdb-movie-metadata\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cf65d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tmdb/tmdb-movie-metadata\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11181ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m movies \u001b[38;5;241m=\u001b[39m movies\u001b[38;5;241m.\u001b[39mmerge(credits,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m movies \u001b[38;5;241m=\u001b[39m movies[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrew\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m---> 10\u001b[0m movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(convert)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m     13\u001b[0m ast\u001b[38;5;241m.\u001b[39mliteral_eval(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 28, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 12, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdventure\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 14, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFantasy\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 878, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScience Fiction\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'convert' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv(r'C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\\tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv(r'C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\\tmdb_5000_credits.csv')\n",
    "movies = movies.merge(credits,on='title')\n",
    "\n",
    "movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
    "\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "\n",
    "import ast\n",
    "ast.literal_eval('[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]')\n",
    "\n",
    "def convert3(text):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(text):\n",
    "        if counter < 3:\n",
    "            L.append(i['name'])\n",
    "        counter+=1\n",
    "    return L \n",
    "\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(lambda x:x[0:3])\n",
    "\n",
    "def fetch_director(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "    return L \n",
    "\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "def collapse(L):\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \",\"\"))\n",
    "    return L1\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(collapse)\n",
    "movies['crew'] = movies['crew'].apply(collapse)\n",
    "movies['genres'] = movies['genres'].apply(collapse)\n",
    "movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(lambda x:x.split())\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "new = movies.drop(columns=['overview','genres','keywords','cast','crew'])\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000,stop_words='english')\n",
    "    \n",
    "vector = cv.fit_transform(new['tags']).toarray()\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vector)\n",
    "new[new['title'] == 'The Lego Movie'].index[0]\n",
    "def recommend(movie):\n",
    "    index = new[new['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])),reverse=True,key = lambda x: x[1])\n",
    "    for i in distances[1:6]:\n",
    "        print(new.iloc[i[0]].title)\n",
    "import pickle\n",
    "pickle.dump(new,open('movie_list.pkl','wb'))\n",
    "pickle.dump(similarity,open('similarity.pkl','wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c0fd89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14224\\3748212641.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# Load datasets\n",
    "movies = pd.read_csv(r'C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\\tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv(r'C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\\tmdb_5000_credits.csv')\n",
    "\n",
    "# Merge on title\n",
    "movies = movies.merge(credits, on='title')\n",
    "\n",
    "# Keep only useful columns\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "\n",
    "# ---------- Step 1: Define required conversion functions ----------\n",
    "\n",
    "# Converts stringified list of dicts to list of names\n",
    "def convert(text):\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            L.append(i['name'])\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "# Converts cast string to top 3 cast names\n",
    "def convert3(text):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(text):\n",
    "        if counter < 3:\n",
    "            L.append(i['name'])\n",
    "            counter += 1\n",
    "    return L\n",
    "\n",
    "# Fetch director name from crew\n",
    "def fetch_director(text):\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            if i['job'] == 'Director':\n",
    "                L.append(i['name'])\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "# Removes spaces from multi-word names\n",
    "def collapse(L):\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \", \"\"))\n",
    "    return L1\n",
    "\n",
    "# ---------- Step 2: Apply functions to columns ----------\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(convert3)\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "# Preprocess all text columns\n",
    "movies['cast'] = movies['cast'].apply(collapse)\n",
    "movies['crew'] = movies['crew'].apply(collapse)\n",
    "movies['genres'] = movies['genres'].apply(collapse)\n",
    "movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "\n",
    "# Split overview into words\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "\n",
    "# Combine all text into a single \"tags\" column\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "\n",
    "# Drop unused columns\n",
    "new = movies[['movie_id', 'title', 'tags']]\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# ---------- Step 3: Vectorization using Bag of Words ----------\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vector = cv.fit_transform(new['tags']).toarray()\n",
    "\n",
    "# ---------- Step 4: Similarity Calculation ----------\n",
    "similarity = cosine_similarity(vector)\n",
    "\n",
    "# ---------- Step 5: Recommendation Function ----------\n",
    "def recommend(movie):\n",
    "    index = new[new['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "    print(f\"\\nTop 5 recommendations for '{movie}':\")\n",
    "    for i in distances[1:6]:\n",
    "        print(new.iloc[i[0]].title)\n",
    "\n",
    "# ---------- Step 6: Save the model ----------\n",
    "pickle.dump(new, open('movie_list.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('similarity.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52befeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_864\\1622920493.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_864\\1622920493.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new['cluster'] = kmeans.labels_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved model/movie_list.pkl and similarity.pkl\n",
      "\n",
      "Top 5 recommended movies for 'The Lego Movie' (sorted by rating/popularity):\n",
      "The Book of Life â€” Rating: 7.3, Popularity: 34.89\n",
      "National Lampoon's Vacation â€” Rating: 7.1, Popularity: 22.84\n",
      "Despicable Me 2 â€” Rating: 7.0, Popularity: 136.89\n",
      "The Croods â€” Rating: 6.8, Popularity: 64.18\n",
      "The Boxtrolls â€” Rating: 6.6, Popularity: 30.66\n",
      "\n",
      "Cluster-based recommendations for 'The Lego Movie':\n",
      "Agent Cody Banks 2: Destination London\n",
      "Tombstone\n",
      "The Hunger Games: Mockingjay - Part 2\n",
      "City of Ember\n",
      "300: Rise of an Empire\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "\n",
    "# Load datasets\n",
    "movies = pd.read_csv(r'C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\\tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv(r'C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\\tmdb_5000_credits.csv')\n",
    "\n",
    "# Merge on title\n",
    "movies = movies.merge(credits, on='title')\n",
    "\n",
    "# Select required columns\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew', 'vote_average', 'popularity']]\n",
    "\n",
    "# Helper functions\n",
    "def convert(text):\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            L.append(i['name'])\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def convert3(text):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            if counter < 3:\n",
    "                L.append(i['name'])\n",
    "                counter += 1\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def fetch_director(text):\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            if i['job'] == 'Director':\n",
    "                L.append(i['name'])\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def collapse(L):\n",
    "    return [i.replace(\" \", \"\") for i in L]\n",
    "\n",
    "# Apply transformations\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(convert3)\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(collapse)\n",
    "movies['crew'] = movies['crew'].apply(collapse)\n",
    "movies['genres'] = movies['genres'].apply(collapse)\n",
    "movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "\n",
    "# Create tags column\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "new = movies[['movie_id', 'title', 'tags', 'vote_average', 'popularity']]\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Vectorize tags\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vector = cv.fit_transform(new['tags']).toarray()\n",
    "\n",
    "# Cosine similarity\n",
    "similarity = cosine_similarity(vector)\n",
    "\n",
    "# KMeans clustering (ML model)\n",
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "kmeans.fit(vector)\n",
    "new['cluster'] = kmeans.labels_\n",
    "\n",
    "# Enhanced recommendation with popularity and rating sorting\n",
    "def recommend(movie):\n",
    "    index = new[new['title'] == movie].index[0]\n",
    "    distances = list(enumerate(similarity[index]))\n",
    "    distances = sorted(distances, reverse=True, key=lambda x: x[1])\n",
    "    \n",
    "    movie_list = []\n",
    "    for i in distances[1:11]:  # Top 10 similar movies\n",
    "        movie_list.append((\n",
    "            new.iloc[i[0]].title,\n",
    "            movies.iloc[i[0]]['vote_average'],\n",
    "            movies.iloc[i[0]]['popularity']\n",
    "        ))\n",
    "    \n",
    "    # Sort by rating then popularity\n",
    "    movie_list = sorted(movie_list, reverse=True, key=lambda x: (x[1], x[2]))\n",
    "    \n",
    "    print(f\"\\nTop 5 recommended movies for '{movie}' (sorted by rating/popularity):\")\n",
    "    for movie, rating, pop in movie_list[:5]:\n",
    "        print(f\"{movie} â€” Rating: {rating}, Popularity: {pop:.2f}\")\n",
    "\n",
    "# Cluster-based alternative recommendation\n",
    "def recommend_by_cluster(movie):\n",
    "    index = new[new['title'] == movie].index[0]\n",
    "    cluster_label = new.iloc[index]['cluster']\n",
    "    cluster_movies = new[(new['cluster'] == cluster_label) & (new.index != index)]\n",
    "    \n",
    "    print(f\"\\nCluster-based recommendations for '{movie}':\")\n",
    "    for title in cluster_movies['title'].sample(min(5, len(cluster_movies))).values:\n",
    "        print(title)\n",
    "\n",
    "# Save model and data\n",
    "import os\n",
    "\n",
    "# ðŸ”’ Create model folder if it doesn't exist\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "\n",
    "# ðŸ’¾ Save processed data and similarity matrix\n",
    "pickle.dump(new, open('model/movie_list.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('model/similarity.pkl', 'wb'))\n",
    "\n",
    "print(\"âœ… Saved model/movie_list.pkl and similarity.pkl\")\n",
    "\n",
    "# Example usage\n",
    "recommend(\"The Lego Movie\")\n",
    "recommend_by_cluster(\"The Lego Movie\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
